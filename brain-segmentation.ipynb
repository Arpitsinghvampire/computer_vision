{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7436152,"sourceType":"datasetVersion","datasetId":4327785},{"sourceId":332401,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":278631,"modelId":299534},{"sourceId":332402,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":278632,"modelId":299535},{"sourceId":348335,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":290885,"modelId":311576},{"sourceId":348341,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":290889,"modelId":311578},{"sourceId":354015,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":295310,"modelId":315918},{"sourceId":355614,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":296600,"modelId":317207},{"sourceId":359907,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":299561,"modelId":320139},{"sourceId":359910,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":299564,"modelId":320142}],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfile_names_train = []\nfile_names_test = []\nfile_names_valid=  []\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        if \"valid\" in os.path.join(dirname,filename):\n            file_names_valid.append(os.path.join(dirname,filename))\n        if \"train\" in os.path.join(dirname,filename):\n            file_names_train.append(os.path.join(dirname,filename))\n\n        if  \"test\" in os.path.join(dirname,filename):\n            file_names_test.append(os.path.join(dirname,filename))\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.356258Z","iopub.status.idle":"2025-04-28T12:28:06.356482Z","shell.execute_reply.started":"2025-04-28T12:28:06.356382Z","shell.execute_reply":"2025-04-28T12:28:06.356392Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(file_names_train))\nprint(len(file_names_test))\nprint(len(file_names_valid))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.357296Z","iopub.status.idle":"2025-04-28T12:28:06.357557Z","shell.execute_reply.started":"2025-04-28T12:28:06.357440Z","shell.execute_reply":"2025-04-28T12:28:06.357452Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"l = [file for file in file_names_train if \"json\" in file]\nprint(l)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.358551Z","iopub.status.idle":"2025-04-28T12:28:06.358779Z","shell.execute_reply.started":"2025-04-28T12:28:06.358669Z","shell.execute_reply":"2025-04-28T12:28:06.358681Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"l1 = [file for file in file_names_test if \"json\" in file]\nprint(l1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.360138Z","iopub.status.idle":"2025-04-28T12:28:06.360350Z","shell.execute_reply.started":"2025-04-28T12:28:06.360253Z","shell.execute_reply":"2025-04-28T12:28:06.360262Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"l2 = [file for file in file_names_valid if \"json\" in file]\nprint(l2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.361398Z","iopub.status.idle":"2025-04-28T12:28:06.361649Z","shell.execute_reply.started":"2025-04-28T12:28:06.361542Z","shell.execute_reply":"2025-04-28T12:28:06.361553Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport csv\n\n# Load the COCO-style JSON file\nwith open('/kaggle/input/brain-tumor-image-dataset-semantic-segmentation/train/_annotations.coco.json', 'r') as f:\n    data = json.load(f)\n\n# Create a mapping from image_id to file_name\nimage_id_to_filename = {img['id']: img['file_name'] for img in data['images']}\n\n# Open a CSV file to write\nwith open('annotations.csv', mode='w', newline='') as file:\n    writer = csv.writer(file)\n    # Write header\n    writer.writerow(['image_id', 'file_name', 'category_id', 'bbox'])\n\n    # Write each annotation\n    for ann in data['annotations']:\n        image_id = ann['image_id']\n        file_name = image_id_to_filename.get(image_id, \"unknown\")\n        category_id = ann['category_id']\n        bbox = json.dumps(ann['bbox'])  # <-- Convert list to JSON string\n\n        writer.writerow([image_id, file_name, category_id, bbox])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.362858Z","iopub.status.idle":"2025-04-28T12:28:06.363189Z","shell.execute_reply.started":"2025-04-28T12:28:06.363013Z","shell.execute_reply":"2025-04-28T12:28:06.363026Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport json\n\ndf = pd.read_csv('annotations.csv')\ndf['bbox'] = df['bbox'].apply(json.loads)  # convert JSON string back to list\n\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.364212Z","iopub.status.idle":"2025-04-28T12:28:06.364512Z","shell.execute_reply.started":"2025-04-28T12:28:06.364361Z","shell.execute_reply":"2025-04-28T12:28:06.364373Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport csv\n\n# Load the COCO-style JSON file\nwith open('/kaggle/input/brain-tumor-image-dataset-semantic-segmentation/test/_annotations.coco.json', 'r') as f:\n    data = json.load(f)\n\n# Create a mapping from image_id to file_name\nimage_id_to_filename = {img['id']: img['file_name'] for img in data['images']}\n\n# Open a CSV file to write\nwith open('annotations.csv', mode='w', newline='') as file:\n    writer = csv.writer(file)\n    # Write header\n    writer.writerow(['image_id', 'file_name', 'category_id', 'bbox'])\n\n    # Write each annotation\n    for ann in data['annotations']:\n        image_id = ann['image_id']\n        file_name = image_id_to_filename.get(image_id, \"unknown\")\n        category_id = ann['category_id']\n        bbox = json.dumps(ann['bbox'])  # <-- Convert list to JSON string\n\n        writer.writerow([image_id, file_name, category_id, bbox])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.365242Z","iopub.status.idle":"2025-04-28T12:28:06.365461Z","shell.execute_reply.started":"2025-04-28T12:28:06.365362Z","shell.execute_reply":"2025-04-28T12:28:06.365371Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport json\n\ndf_test = pd.read_csv('annotations.csv')\ndf_test['bbox'] = df_test['bbox'].apply(json.loads)  # convert JSON string back to list\n\ndf_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.366598Z","iopub.status.idle":"2025-04-28T12:28:06.366849Z","shell.execute_reply.started":"2025-04-28T12:28:06.366736Z","shell.execute_reply":"2025-04-28T12:28:06.366748Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport csv\n\n# Load the COCO-style JSON file\nwith open('/kaggle/input/brain-tumor-image-dataset-semantic-segmentation/valid/_annotations.coco.json', 'r') as f:\n    data = json.load(f)\n\n# Create a mapping from image_id to file_name\nimage_id_to_filename = {img['id']: img['file_name'] for img in data['images']}\n\n# Open a CSV file to write\nwith open('annotations.csv', mode='w', newline='') as file:\n    writer = csv.writer(file)\n    # Write header\n    writer.writerow(['image_id', 'file_name', 'category_id', 'bbox'])\n\n    # Write each annotation\n    for ann in data['annotations']:\n        image_id = ann['image_id']\n        file_name = image_id_to_filename.get(image_id, \"unknown\")\n        category_id = ann['category_id']\n        bbox = json.dumps(ann['bbox'])  # <-- Convert list to JSON string\n\n        writer.writerow([image_id, file_name, category_id, bbox])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.367831Z","iopub.status.idle":"2025-04-28T12:28:06.368025Z","shell.execute_reply.started":"2025-04-28T12:28:06.367932Z","shell.execute_reply":"2025-04-28T12:28:06.367940Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport json\n\ndf_valid = pd.read_csv('annotations.csv')\ndf_valid['bbox'] = df_valid['bbox'].apply(json.loads)  # convert JSON string back to list\n\ndf_valid","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.368832Z","iopub.status.idle":"2025-04-28T12:28:06.369043Z","shell.execute_reply.started":"2025-04-28T12:28:06.368945Z","shell.execute_reply":"2025-04-28T12:28:06.368954Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#lets plot a image \nimport matplotlib.pyplot as plt\n\nm =\"/kaggle/input/brain-tumor-image-dataset-semantic-segmentation/train/\"+ df[\"file_name\"][0]\nprint(m)\n\nm1 = plt.imread(m)\nplt.imshow(m1)\nplt.plot()\nplt.axis(\"off\")\nprint(m1.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.369671Z","iopub.status.idle":"2025-04-28T12:28:06.369862Z","shell.execute_reply.started":"2025-04-28T12:28:06.369772Z","shell.execute_reply":"2025-04-28T12:28:06.369780Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def image_file(csv_files):\n    return_numpy =[]\n    for i in range(len(csv_files['bbox'])):\n        l = \"/kaggle/input/brain-tumor-image-dataset-semantic-segmentation/train/\"+csv_files['file_name'][i]\n        numpy_array = plt.imread(l)\n        return_numpy.append(numpy_array)\n    return return_numpy\n\ndef image_file1(csv_files):\n    return_numpy =[]\n    for i in range(len(csv_files['bbox'])):\n        l = \"/kaggle/input/brain-tumor-image-dataset-semantic-segmentation/test/\"+csv_files['file_name'][i]\n        numpy_array = plt.imread(l)\n        return_numpy.append(numpy_array)\n    return return_numpy\n\ndef image_file2(csv_files):\n    return_numpy =[]\n    for i in range(len(csv_files['bbox'])):\n        l = \"/kaggle/input/brain-tumor-image-dataset-semantic-segmentation/valid/\"+csv_files['file_name'][i]\n        numpy_array = plt.imread(l)\n        return_numpy.append(numpy_array)\n    return return_numpy\n\nimage_numpy_array_train = image_file(df)\nimage_numpy_array_train = np.asarray(image_numpy_array_train)\n\nimage_numpy_array_test = image_file1(df_test)\nimage_numpy_array_test = np.asarray(image_numpy_array_test)\n\nimage_numpy_array_valid = image_file2(df_valid)\nimage_numpy_array_valid = np.asarray(image_numpy_array_valid)\n\nprint(image_numpy_array_train.shape)\nprint(image_numpy_array_train[0].shape)\nprint(image_numpy_array_test.shape)\nprint(image_numpy_array_test[0].shape)\nprint(image_numpy_array_valid.shape)\nprint(image_numpy_array_valid[0].shape)\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.371135Z","iopub.status.idle":"2025-04-28T12:28:06.371360Z","shell.execute_reply.started":"2025-04-28T12:28:06.371255Z","shell.execute_reply":"2025-04-28T12:28:06.371264Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#[1,9] for tumour\n#[0,1] for non tumour\nprint(len(df['bbox'][0]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.371835Z","iopub.status.idle":"2025-04-28T12:28:06.372133Z","shell.execute_reply.started":"2025-04-28T12:28:06.371985Z","shell.execute_reply":"2025-04-28T12:28:06.372000Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## here we try to prepare the data by converting the image into a 2 dimensional image\n#which contains the one hot encoded vector since there are 2 classes , we \nimport math\ndef  convert_image_to_semantic_map(input_csv_file):\n    semantic_mapping = []\n    for i in range(len(input_csv_file['bbox'])):\n        zero_matrix = np.zeros((640,640,1),dtype = np.uint8)\n        l = list(input_csv_file['bbox'][i])\n        for i in range(l[0],math.ceil(l[0]+l[2])):\n            for j in range(l[1],math.ceil(l[1]+l[3])):\n                zero_matrix[i,j] =1\n        \n        semantic_mapping.append(zero_matrix)\n\n    return semantic_mapping\n \nsemantic_maps_train = convert_image_to_semantic_map(df)\nsemantic_maps_train = np.asarray(semantic_maps_train)\n\n\nsemantic_maps_test = convert_image_to_semantic_map(df_test)\nsemantic_maps_test = np.asarray(semantic_maps_test)\n\nsemantic_maps_valid = convert_image_to_semantic_map(df_valid)\nsemantic_maps_valid = np.asarray(semantic_maps_valid)\n\nprint(semantic_maps_train.shape)\nprint(semantic_maps_test.shape)\nprint(semantic_maps_valid.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.373230Z","iopub.status.idle":"2025-04-28T12:28:06.373444Z","shell.execute_reply.started":"2025-04-28T12:28:06.373345Z","shell.execute_reply":"2025-04-28T12:28:06.373354Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#now we have the original image and the corresponding semantic map\n#Now lets create the baseline unet model \n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\n\nfrom tensorflow.keras.layers import (\n    Conv2D, MaxPooling2D, UpSampling2D, GlobalAveragePooling2D, AveragePooling2D, \n    Dense, Concatenate, Input, Multiply\n)\nfrom tensorflow.keras.layers import BatchNormalization\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Lambda\nfrom tensorflow.keras.initializers import HeNormal\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.374366Z","iopub.status.idle":"2025-04-28T12:28:06.374575Z","shell.execute_reply.started":"2025-04-28T12:28:06.374476Z","shell.execute_reply":"2025-04-28T12:28:06.374485Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#now first lets create the baseline unet model \ndef convolution_block(previous_layer, number_of_filters):\n    CONV_1 = Conv2D(number_of_filters,padding = \"same\",activation = \"relu\", kernel_size = (3,3))(previous_layer)\n    CONV_2 = Conv2D(number_of_filters, padding = \"same\", activation = \"relu\", kernel_size = (3,3))(CONV_1)\n    return CONV_2\n\ninput = Input((640,640,3))\n#now we pass it through a layer of convolution layers \ninput_conv = Conv2D(16,(3,3),activation = 'relu',padding = 'same',kernel_initializer = HeNormal())(input)\nk_1 = convolution_block(input_conv,16)\nmaxpool_layer = MaxPooling2D()(k_1)\nk_2 = convolution_block(maxpool_layer,32)\nmaxpool_layer2 = MaxPooling2D()(k_2)\nk_3 = convolution_block(maxpool_layer2,64)\nmaxpool_layer3 = MaxPooling2D()(k_3)\nk_4  = convolution_block(maxpool_layer3, 128)\n#now i have coded the  encoder layer of the unet , now lets try to code the decoder layer of the unet mode \nk_5  = convolution_block(k_4,128)\nk_5 = Conv2D(64,(3,3),padding= \"same\",activation = \"relu\")(k_5)\nupsample_1 = UpSampling2D((2,2))(k_5)\nconcatenate = Concatenate()([upsample_1,k_3])\nk_6 = convolution_block(concatenate,64)\nupsample_2 = UpSampling2D((2,2))(k_6)\nconvolution = Conv2D(32,(3,3),padding = \"same\", activation = \"relu\")(upsample_2)\nk_7 = Concatenate()([convolution,k_2])\nk_8 = convolution_block(k_7,32)\n\nupsample_2 = UpSampling2D((2,2))(k_8)\nk_9 = Conv2D(5,(3,3), padding = \"same\", activation = \"relu\")(upsample_2)\nk_10 = Concatenate()([k_9,k_1])\nk_12 = convolution_block(k_10 ,3)\nk_13 = convolution_block(k_10 ,5)\nk_14 = convolution_block(k_10 ,10)\nk_13 = Conv2D(1,(1,1), activation = \"sigmoid\", padding = \"same\")(k_12)\n\n\n#now lets wrap the model \nbaseline_unet_model = Model(inputs = input, outputs = k_13)\nbaseline_unet_model.summary()\n\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.375115Z","iopub.status.idle":"2025-04-28T12:28:06.375391Z","shell.execute_reply.started":"2025-04-28T12:28:06.375246Z","shell.execute_reply":"2025-04-28T12:28:06.375257Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#now we have denormalized the image . \n#next we now try to build the unet model , infused with attention \nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Lambda\n\nfrom tensorflow.keras.layers import (\n    Conv2D, MaxPooling2D, UpSampling2D, GlobalAveragePooling2D, AveragePooling2D, \n    Dense, Concatenate, Input, Multiply\n)\nfrom tensorflow.keras.layers import BatchNormalization\n\nfrom tensorflow.keras.models import Model\n\nclass TeacherNetwork:\n    def __init__(self, weight, reduction_amount):\n        self.activation = \"relu\"\n        self.padding = \"same\"\n        self.kernel_size = (3, 3)\n        self.weight = weight  # Importance given to avg pooling\n        self.reduction_amount = reduction_amount\n\n    def encoder_layer(self, filters, last_layer):\n        output1 = Conv2D(filters, self.kernel_size, activation=self.activation, padding=self.padding)(last_layer)\n        output2 = Conv2D(filters, self.kernel_size, activation=self.activation, padding=self.padding)(output1)\n        batchnorm4 = BatchNormalization()(output2)\n        maxpool_layer = MaxPooling2D()(batchnorm4)\n        return output2, maxpool_layer\n\n    def decoder_layer(self, filters, last_layer):\n        output1 = Conv2D(filters, self.kernel_size, activation=self.activation, padding=self.padding)(last_layer)\n        batchnorm3= BatchNormalization()(output1)\n        output2 = Conv2D(filters, self.kernel_size, activation=self.activation, padding=self.padding)(batchnorm3)\n        upsample_layer = UpSampling2D(size=(2,2), interpolation=\"nearest\")(output2)\n        return upsample_layer\n    def channel_attention_layer(self, input_tensor, filters):\n        pooled_tensor = MaxPooling2D()(input_tensor)\n        avg_pool = GlobalAveragePooling2D()(pooled_tensor)\n\n        avg_pool1 = AveragePooling2D((2, 2))(input_tensor)\n        avg_pool2 = GlobalAveragePooling2D()(avg_pool1)\n\n    # First branch\n        dense_layer = Dense(filters, activation=\"relu\")(avg_pool)\n        dense_layer1 = Dense(filters // 2, activation=\"relu\")(dense_layer)\n        dense_layer2 = Dense(filters, activation=\"relu\")(dense_layer1)\n\n    # Second branch\n        dense_layer3 = Dense(filters, activation=\"relu\")(avg_pool2)\n        dense_layer4 = Dense(filters // 2, activation=\"relu\")(dense_layer3)\n        dense_layer5 = Dense(filters, activation=\"relu\")(dense_layer4)\n\n    # Concatenate and final squeeze\n        concatenate_layer = Concatenate(axis=-1)([dense_layer2, dense_layer5])\n        dense_layer6 = Dense(filters, activation=\"sigmoid\")(concatenate_layer)\n\n    # ✅ Corrected reshape\n        attention = tf.keras.layers.Reshape((1, 1, filters))(dense_layer6)\n        output_filters = input_tensor * attention\n        return output_filters\n\n\n    def spatial_attention_layer(self, input_tensor, filters):\n        input_tensor1 = self.channel_attention_layer(input_tensor, filters)\n\n        maxpool_tensor = MaxPooling2D((2, 2))(input_tensor1)\n        average_tensor = AveragePooling2D((2, 2))(input_tensor1)\n\n        # Adjust importance\n        average_tensor = self.weight * average_tensor\n        maxpool_tensor = (1 - self.weight) * maxpool_tensor\n\n        concatenated_filters = Concatenate(axis=-1)([average_tensor, maxpool_tensor])\n        convolution_filter = Conv2D(filters, (3,3), padding=\"same\", activation=\"relu\",kernel_initializer =  HeNormal())(concatenated_filters)\n        batchnorm5 = BatchNormalization()(convolution_filter)\n        convolution_filter2 = Conv2D(1, (3,3), padding=\"same\", activation=\"sigmoid\")(batchnorm5)\n        batchnorm6 = BatchNormalization()(convolution_filter2)\n\n        upsampled_filter = UpSampling2D((2,2))(batchnorm6)\n        spatial_filter= input_tensor1*upsampled_filter\n        return spatial_filter\n\n    def attention_block(self, input_tensor, filters):\n        return self.spatial_attention_layer(input_tensor, filters)\n\n    def build_model(self, input_shape):\n        inputs = Input(shape=input_shape)\n        input_conv = Conv2D(16,(3,3),padding = \"same\",activation =\"relu\" , kernel_initializer = HeNormal())(inputs)\n        \n        enc1, pool1 = self.encoder_layer(16, input_conv)\n        enc2, pool2 = self.encoder_layer(32, pool1)\n        enc3, pool3 = self.encoder_layer(32, pool2)\n        enc4, _ = self.encoder_layer(64, pool3)\n\n        att1 = self.attention_block(enc1, 16)\n        att2 = self.attention_block(enc2, 32)\n        att3 = self.attention_block(enc3, 32)\n\n\n        \n        dec6 = self.decoder_layer(64, enc4)\n        concat5 = Concatenate(axis=-1)([att3, dec6])\n        dec5 = self.decoder_layer(32, concat5)\n\n        concat4 = Concatenate(axis=-1)([att2, dec5])\n        dec4 = self.decoder_layer(32, concat4)\n\n        concat3 = Concatenate(axis=-1)([att1, dec4])\n        dec3 = self.decoder_layer(16, concat3)\n\n        maxpool_layer = MaxPooling2D()(dec3)\n\n        concat1 = Concatenate(axis=-1)([att1, maxpool_layer])\n        batchnorm11 = BatchNormalization()(concat1)\n        output_tensor1 = Conv2D(20, (3, 3), activation=self.activation, padding=self.padding)(batchnorm11)\n        output_tensor1 = Conv2D(20, (3, 3), activation=self.activation, padding=self.padding)(batchnorm11)\n\n        output_tensor1 = Conv2D(15, (3, 3), activation=self.activation, padding=self.padding)(batchnorm11)\n        output_tensor1 = Conv2D(15, (3, 3), activation=self.activation, padding=self.padding)(batchnorm11)\n        \n        batchnorm12 = BatchNormalization()(output_tensor1)\n        output_tensor3 = Conv2D(10,(3,3),activation = self.activation,padding = self.padding)(batchnorm12)\n        \n        output_tensor4 = Conv2D(5,(3,3),activation = \"relu\",padding = \"same\")(output_tensor3)\n        output_tensor2 = Conv2D(1, (1, 1), activation=\"sigmoid\", padding=self.padding)(output_tensor3)\n        \n\n        #output_tensor3 = Lambda(lambda x: tf.squeeze(x, axis=-1))(output_tensor2)\n\n\n        return Model(inputs, output_tensor2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.376437Z","iopub.status.idle":"2025-04-28T12:28:06.376721Z","shell.execute_reply.started":"2025-04-28T12:28:06.376566Z","shell.execute_reply":"2025-04-28T12:28:06.376580Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#after creating the class , lets now create an object \n\nteacher_unet = TeacherNetwork(0.5,2)\nteacher_model = teacher_unet.build_model((640,640,3))\nteacher_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.377766Z","iopub.status.idle":"2025-04-28T12:28:06.378050Z","shell.execute_reply.started":"2025-04-28T12:28:06.377912Z","shell.execute_reply":"2025-04-28T12:28:06.377927Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_model(teacher_model,show_layer_names = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.378920Z","iopub.status.idle":"2025-04-28T12:28:06.379221Z","shell.execute_reply.started":"2025-04-28T12:28:06.379037Z","shell.execute_reply":"2025-04-28T12:28:06.379046Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.metrics import MeanIoU\n\n\ndef dice_score(y_true, y_pred, smooth=1e-6):\n    y_true = tf.cast(y_true,tf.float32)\n    y_pred = tf.cast(y_pred,tf.float32)\n    \n    y_true_f = tf.reshape(y_true, [-1])\n    y_pred_f = tf.reshape(y_pred, [-1])\n    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.380209Z","iopub.status.idle":"2025-04-28T12:28:06.380480Z","shell.execute_reply.started":"2025-04-28T12:28:06.380330Z","shell.execute_reply":"2025-04-28T12:28:06.380351Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Now we have created the test train and the valid set\n#we now compile the model \nfrom tensorflow.keras.optimizers import Adam\nteacher_model.compile(metrics = [dice_score],optimizer = Adam(learning_rate =0.0001),loss =\"binary_crossentropy\")\nbaseline_unet_model.compile(metrics = [dice_score],optimizer = Adam(learning_rate =0.0001),loss =\"binary_crossentropy\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.381361Z","iopub.status.idle":"2025-04-28T12:28:06.381642Z","shell.execute_reply.started":"2025-04-28T12:28:06.381488Z","shell.execute_reply":"2025-04-28T12:28:06.381499Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(image_numpy_array_valid.shape)\nprint(semantic_maps_valid.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.382268Z","iopub.status.idle":"2025-04-28T12:28:06.382553Z","shell.execute_reply.started":"2025-04-28T12:28:06.382441Z","shell.execute_reply":"2025-04-28T12:28:06.382452Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = baseline_unet_model.fit(image_numpy_array_train,semantic_maps_train,validation_data = (image_numpy_array_valid,semantic_maps_valid),epochs = 50 , verbose = 1,batch_size = 7  )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.383642Z","iopub.status.idle":"2025-04-28T12:28:06.383902Z","shell.execute_reply.started":"2025-04-28T12:28:06.383766Z","shell.execute_reply":"2025-04-28T12:28:06.383778Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history1 = teacher_model.fit(image_numpy_array_train,semantic_maps_train,validation_data = (image_numpy_array_valid,semantic_maps_valid),epochs = 50 , verbose = 1,batch_size = 3  )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.385135Z","iopub.status.idle":"2025-04-28T12:28:06.385407Z","shell.execute_reply.started":"2025-04-28T12:28:06.385261Z","shell.execute_reply":"2025-04-28T12:28:06.385273Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#now lets save the model\n\nbaseline_unet_model.save('/kaggle/working/baseline_unet_model3.keras')\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.386090Z","iopub.status.idle":"2025-04-28T12:28:06.386353Z","shell.execute_reply.started":"2025-04-28T12:28:06.386235Z","shell.execute_reply":"2025-04-28T12:28:06.386246Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"teacher_model.save(\"/kaggle/working/teacher_modelv4.keras\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.387194Z","iopub.status.idle":"2025-04-28T12:28:06.387575Z","shell.execute_reply.started":"2025-04-28T12:28:06.387414Z","shell.execute_reply":"2025-04-28T12:28:06.387429Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#now lets load  the model \nfrom tensorflow.keras.models import load_model\nfrom keras import config as keras_config\n\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.metrics import MeanIoU\n\ndef dice_score(y_true, y_pred):\n    y_true = tf.cast(y_true,tf.float32)\n    y_pred = tf.cast(y_pred,tf.float32)\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n\n    \n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2*intersection + 0.000001) / (K.sum(y_true_f) + K.sum(y_pred_f) + 0.00001)\n\n\nbaseline_model = load_model(\"/kaggle/input/baseline_unet_model_final/keras/default/1/baseline_unet_model2.keras\",custom_objects = {\"dice_score\":dice_score})\n\n\nteacher_model = load_model(\"/kaggle/input/teacher_model_final/keras/default/1/teacher_modelv4.keras\",\n                           custom_objects={\"dice_score\": dice_score})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.388242Z","iopub.status.idle":"2025-04-28T12:28:06.388470Z","shell.execute_reply.started":"2025-04-28T12:28:06.388365Z","shell.execute_reply":"2025-04-28T12:28:06.388377Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#now lets plot some predictions \nimport matplotlib.pyplot as plt\n\n# Extract values\nacc = history.history['dice_score']\nval_acc = history.history['val_dice_score']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(len(acc))\n\n# Plot accuracy\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Plot loss\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.389663Z","iopub.status.idle":"2025-04-28T12:28:06.390392Z","shell.execute_reply.started":"2025-04-28T12:28:06.390169Z","shell.execute_reply":"2025-04-28T12:28:06.390188Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Extract values\nacc = history1.history['dice_score']\nval_acc = history1.history['val_dice_score']\nloss = history1.history['loss']\nval_loss = history1.history['val_loss']\nepochs_range = range(len(acc))\n\n# Plot accuracy\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Plot loss\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.391115Z","iopub.status.idle":"2025-04-28T12:28:06.391438Z","shell.execute_reply.started":"2025-04-28T12:28:06.391266Z","shell.execute_reply":"2025-04-28T12:28:06.391280Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#now lets plot some predictions of the model \nfor i in range(10):\n    k = image_numpy_array_test[i]\n    k = np.expand_dims(k,axis = 0)\n    seamntic_map_original = semantic_maps_test[i]\n    #we get the predictions from the baseline unet model and the teacher model \n    prediction_baseline = baseline_unet_model.predict(k)\n    prediction_teacher = teacher_model.predict(k)\n    print(len(prediction_teacher[0]))\n    #now after getting the predictions , we need to squeeze the dimension\n    prediction_baseline = np.asarray(prediction_baseline)\n    prediction_teacher1 = np.asarray(prediction_teacher[0])\n    \n    prediction_baseline = prediction_baseline.squeeze()\n\n    #here we need to plot the diagram \n    # Plotting both predictions side by side\n    plt.figure(figsize=(10, 4))\n\n    plt.subplot(1, 2, 1)\n    plt.imshow(prediction_teacher1, cmap='gray')\n    plt.title(\"Teacher Prediction\")\n    plt.axis('off')\n    \n    plt.subplot(1, 2, 2)\n    plt.imshow(seamntic_map_original, cmap='gray')\n    plt.title(\"Original Prediction\")\n    plt.axis('off')\n\n    plt.suptitle(f\"Prediction Comparison - Sample {i+1}\")\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.392576Z","iopub.status.idle":"2025-04-28T12:28:06.392907Z","shell.execute_reply.started":"2025-04-28T12:28:06.392736Z","shell.execute_reply":"2025-04-28T12:28:06.392754Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"teacher_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.394672Z","iopub.status.idle":"2025-04-28T12:28:06.395184Z","shell.execute_reply.started":"2025-04-28T12:28:06.394999Z","shell.execute_reply":"2025-04-28T12:28:06.395014Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from keras.utils import plot_model \nplot_model(teacher_model , show_layer_names = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.396302Z","iopub.status.idle":"2025-04-28T12:28:06.396538Z","shell.execute_reply.started":"2025-04-28T12:28:06.396432Z","shell.execute_reply":"2025-04-28T12:28:06.396441Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for layer in teacher_model.layers:\n    print(layer)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.397679Z","iopub.status.idle":"2025-04-28T12:28:06.397988Z","shell.execute_reply.started":"2025-04-28T12:28:06.397828Z","shell.execute_reply":"2025-04-28T12:28:06.397841Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"baseline_unet_model.summary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.398735Z","iopub.status.idle":"2025-04-28T12:28:06.399021Z","shell.execute_reply.started":"2025-04-28T12:28:06.398877Z","shell.execute_reply":"2025-04-28T12:28:06.398890Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# List of layers whose names contain 'multiply'\nmultiply_layers = [layer for layer in teacher_model.layers if \"Multiply\" in layer.name]\n\n# Print them\nfor layer in multiply_layers:\n    print(layer.name)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.400075Z","iopub.status.idle":"2025-04-28T12:28:06.400413Z","shell.execute_reply.started":"2025-04-28T12:28:06.400244Z","shell.execute_reply":"2025-04-28T12:28:06.400258Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for layer in teacher_model.layers:\n    layer.trainable = False\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.401364Z","iopub.status.idle":"2025-04-28T12:28:06.401657Z","shell.execute_reply.started":"2025-04-28T12:28:06.401482Z","shell.execute_reply":"2025-04-28T12:28:06.401494Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Conv2D, AveragePooling2D, UpSampling2D, Concatenate\nfrom tensorflow.keras.models import Model\n\ndef convolution_block(number_of_filters,previous_layer):\n    conv_1= Conv2D(number_of_filters,(3,3),padding = \"same\", activation = \"relu\")(previous_layer)\n    conv_2 = Conv2D(number_of_filters,(3,3),padding = \"same\",activation = \"relu\")(conv_1)\n    return conv_2\n\ndef channel_attention_mechanism(starting_layer,filters):\n    pooled_tensor = MaxPooling2D()(starting_layer)\n    avg_pool = GlobalAveragePooling2D()(pooled_tensor)\n\n        \n    avg_pool1= AveragePooling2D((2,2))(starting_layer)\n\n    avg_pool2 = GlobalAveragePooling2D()(avg_pool1)\n\n\n    dense_layer = Dense(filters, activation=\"relu\")(avg_pool)\n    dense_layer1 = Dense(filters // 2, activation=\"relu\")(dense_layer)\n    dense_layer2 = Dense(filters, activation=\"relu\")(dense_layer1)\n\n\n    dense_layer3 = Dense(filters, activation=\"relu\")(avg_pool2)\n    dense_layer4 = Dense(filters // 2, activation=\"relu\")(dense_layer3)\n    dense_layer5 = Dense(filters, activation=\"relu\")(dense_layer4)\n\n        #now i concatenate the output of the two \n    concatenate_layer = Concatenate(axis = -1)([dense_layer2,dense_layer5])\n\n    dense_layer6 = Dense(filters, activation = \"sigmoid\")(concatenate_layer)\n\n    dense_layer7 = tf.keras.layers.Reshape((1, 1, filters))(dense_layer6)\n        \n    output_filters = Multiply()([starting_layer, dense_layer7])\n    return output_filters\n\ndef spatial_attention_mechanism(starting_layers,filters):\n    input_tensor1 = channel_attention_mechanism(starting_layers,filters)\n\n    maxpool_tensor = MaxPooling2D((2, 2))(input_tensor1)\n    average_tensor = AveragePooling2D((2, 2))(input_tensor1)\n\n\n    concatenated_filters = Concatenate(axis=-1)([average_tensor, maxpool_tensor])\n    convolution_filter = Conv2D(filters, (3,3), padding=\"same\", activation=\"relu\")(concatenated_filters)\n    batchnorm5 = BatchNormalization()(convolution_filter)\n    convolution_filter2 = Conv2D(1, (3,3), padding=\"same\", activation=\"sigmoid\")(batchnorm5)\n    batchnorm6 = BatchNormalization()(convolution_filter2)\n\n    upsampled_filter = UpSampling2D((2,2))(batchnorm6)\n        \n    spatial_filter = Multiply()([input_tensor1, upsampled_filter])\n    return spatial_filter\n\nintermediate_teacher_model = Model(\n    inputs=teacher_model.input,\n    outputs=teacher_model.get_layer('concatenate_24').output\n)\n\nintermediate_teacher_model1 = Model(\n    inputs = teacher_model.input,\n    outputs=teacher_model.get_layer('concatenate_23').output\n)\n    \n \n# Now we have created the Teacher UNet model; next, we will create the Student model\n#lets create the student model \ninput = Input((640,640,3))\nconv_1 = convolution_block(16,input)  #concatenate here \nspatial_attention_mechanism_student = spatial_attention_mechanism(conv_1,16)\nadded_attention_mechanism1 = intermediate_teacher_model(input)\nconcatenated_layer = Concatenate()([spatial_attention_mechanism_student, added_attention_mechanism1])\nadded_knowledge1 = Conv2D(16,(3,3),padding = \"same\", activation = \"relu\")(concatenated_layer)\n\n\nmaxpool = MaxPooling2D()(conv_1)\nconv_2 = convolution_block(32,maxpool) #concatenate here \nspatial_attention_mechanism_student2 = spatial_attention_mechanism(conv_2,32)\nadded_attention_mechanism2 =intermediate_teacher_model1(input)\nconcatenated_layer3  = Concatenate()([added_attention_mechanism2,spatial_attention_mechanism_student2])\nadded_knowledge3 = Conv2D(16,(3,3),padding = \"same\", activation = \"relu\")(concatenated_layer3)\n\nmaxpool2 = MaxPooling2D()(conv_2)\nconv_4 = convolution_block(32,maxpool2)\nupsample_layer = UpSampling2D((2,2))(conv_4)\nconcatenate_layer  = Concatenate()([upsample_layer,added_knowledge3])\nconv_5 = convolution_block(16,concatenate_layer)\nupsample_layer2 = UpSampling2D((2,2),name = \"up_sampling2d_8\")(conv_5)\nconcatenate_layer2= Concatenate()([upsample_layer2,added_knowledge1])\nconv_6 = convolution_block(5,concatenate_layer2)\nconv_8 = Conv2D(1,(1,1),padding= \"same\",activation = \"sigmoid\")(conv_6)\n\nstudent_model = Model(inputs = input, outputs = conv_8)\n\nstudent_model.summary()\n\n#this also includes parameters of the teacher \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.402618Z","iopub.status.idle":"2025-04-28T12:28:06.402980Z","shell.execute_reply.started":"2025-04-28T12:28:06.402802Z","shell.execute_reply":"2025-04-28T12:28:06.402818Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"intermediate_teacher_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.403991Z","iopub.status.idle":"2025-04-28T12:28:06.404319Z","shell.execute_reply.started":"2025-04-28T12:28:06.404158Z","shell.execute_reply":"2025-04-28T12:28:06.404172Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"intermediate_teacher_model1.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.405467Z","iopub.status.idle":"2025-04-28T12:28:06.405679Z","shell.execute_reply.started":"2025-04-28T12:28:06.405578Z","shell.execute_reply":"2025-04-28T12:28:06.405587Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#now we have the student model which also takes the activations from the teacher .\nfrom tensorflow.keras.optimizers import Adam\n#we now try to fit the student model \nstudent_model.compile(metrics = [dice_score], loss = \"binary_crossentropy\", optimizer = Adam(learning_rate = 0.0001))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.406283Z","iopub.status.idle":"2025-04-28T12:28:06.406594Z","shell.execute_reply.started":"2025-04-28T12:28:06.406431Z","shell.execute_reply":"2025-04-28T12:28:06.406445Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#now lets fit the data to the student model \nhistory = student_model.fit(image_numpy_array_test,semantic_maps_test,validation_data = (image_numpy_array_valid,semantic_maps_valid),epochs = 50 , verbose = 1,batch_size = 5 )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.407798Z","iopub.status.idle":"2025-04-28T12:28:06.408120Z","shell.execute_reply.started":"2025-04-28T12:28:06.407952Z","shell.execute_reply":"2025-04-28T12:28:06.407965Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Extract values\nacc = history.history['dice_score']\nval_acc = history.history['val_dice_score']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(len(acc))\n\n# Plot accuracy\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Plot loss\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-28T12:28:06.408884Z","iopub.status.idle":"2025-04-28T12:28:06.409187Z","shell.execute_reply.started":"2025-04-28T12:28:06.409028Z","shell.execute_reply":"2025-04-28T12:28:06.409040Z"}},"outputs":[],"execution_count":null}]}