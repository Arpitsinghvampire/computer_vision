{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.utils import to_categorical\n\nmnist = keras.datasets.mnist\n(x_train,y_train),(x_test,y_test)= mnist.load_data()\ny_train= to_categorical(y_train,num_classes = 10)\ny_test = to_categorical(y_test,num_classes = 10)\n\n\nx_train_first = x_train[:40000]\ny_train_first = y_train[:40000]\n\nx_train_second = x_train[40000:]\ny_train_second =  y_train[40000:]\n\nx_test_first = x_test[:7000]\ny_test_first = y_test[:7000]\n\nx_test_second = x_test[7000:]\ny_test_second = y_test[7000:]\n\n\n#now we have prepared the data , lets now create the neural network ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-24T16:49:27.973198Z","iopub.execute_input":"2025-02-24T16:49:27.973513Z","iopub.status.idle":"2025-02-24T16:49:48.026764Z","shell.execute_reply.started":"2025-02-24T16:49:27.973486Z","shell.execute_reply":"2025-02-24T16:49:48.025729Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"print(y_train[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T16:49:52.444264Z","iopub.execute_input":"2025-02-24T16:49:52.444597Z","iopub.status.idle":"2025-02-24T16:49:52.449568Z","shell.execute_reply.started":"2025-02-24T16:49:52.444569Z","shell.execute_reply":"2025-02-24T16:49:52.448584Z"}},"outputs":[{"name":"stdout","text":"[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"print(x_train[1].shape)\nprint(len(x_train))\nprint(len(x_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T16:49:55.339829Z","iopub.execute_input":"2025-02-24T16:49:55.340211Z","iopub.status.idle":"2025-02-24T16:49:55.344978Z","shell.execute_reply.started":"2025-02-24T16:49:55.340179Z","shell.execute_reply":"2025-02-24T16:49:55.343885Z"}},"outputs":[{"name":"stdout","text":"(28, 28)\n60000\n10000\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers \nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.utils import plot_model \nfrom tensorflow.keras.models import Model ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T16:49:58.477182Z","iopub.execute_input":"2025-02-24T16:49:58.477537Z","iopub.status.idle":"2025-02-24T16:49:58.485815Z","shell.execute_reply.started":"2025-02-24T16:49:58.477510Z","shell.execute_reply":"2025-02-24T16:49:58.484902Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"#this will be the teacher model \ninput1 = Input(shape=(28,28))\nflatten = Flatten()(input1)\ndense= Dense(784,activation='relu')(flatten)\ndense = Dense(700,activation='relu')(dense)\nbatchNorm = BatchNormalization()(dense)\ndense_1 = Dense(500,activation='relu')(batchNorm)\nBatchNorm= BatchNormalization()(dense_1)\ndense_layer2 = Dense(512,activation = 'relu')(BatchNorm)\ndense_layer3 = Dense(500,activation = 'relu')(dense_layer2)\nBatchNorm1 = BatchNormalization()(dense_layer3)\ndense_layer4= Dense(450,activation='relu')(BatchNorm1)\nDropout2 =Dropout(0.2)(dense_layer4)\ndense_layer5= Dense(400,activation='relu')(Dropout2)\ndense_layer6 = Dense(350,activation='relu')(dense_layer5)\nDropout1 = Dropout(0.3)(dense_layer6)\ndense_layer7 = Dense(256,activation='relu')(Dropout1)\ndense_layer8 = Dense(200,activation= 'relu')(dense_layer7)\nBatchNorm2 = BatchNormalization()(dense_layer8)\ndense_layer9 = Dense(100,activation ='relu')(BatchNorm2)\ndense_layer10 = Dense(10,activation ='sigmoid')(dense_layer9)\nteacher_model =Model(inputs = input1,outputs= dense_layer10)\nteacher_model.summary()\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T16:50:03.224152Z","iopub.execute_input":"2025-02-24T16:50:03.224527Z","iopub.status.idle":"2025-02-24T16:50:03.441473Z","shell.execute_reply.started":"2025-02-24T16:50:03.224494Z","shell.execute_reply":"2025-02-24T16:50:03.440683Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │         \u001b[38;5;34m615,440\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m700\u001b[0m)                 │         \u001b[38;5;34m549,500\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m700\u001b[0m)                 │           \u001b[38;5;34m2,800\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)                 │         \u001b[38;5;34m350,500\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)                 │           \u001b[38;5;34m2,000\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m256,512\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)                 │         \u001b[38;5;34m256,500\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)                 │           \u001b[38;5;34m2,000\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m450\u001b[0m)                 │         \u001b[38;5;34m225,450\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m450\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)                 │         \u001b[38;5;34m180,400\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m350\u001b[0m)                 │         \u001b[38;5;34m140,350\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m350\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m89,856\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │          \u001b[38;5;34m51,400\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │             \u001b[38;5;34m800\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m20,100\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,010\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">615,440</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">700</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">549,500</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">700</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,800</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">350,500</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,000</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">256,512</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">256,500</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,000</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">450</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">225,450</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">450</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">180,400</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">350</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">140,350</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">350</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">89,856</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">51,400</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,100</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,744,618\u001b[0m (10.47 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,744,618</span> (10.47 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,740,818\u001b[0m (10.46 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,740,818</span> (10.46 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,800\u001b[0m (14.84 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,800</span> (14.84 KB)\n</pre>\n"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"\nteacher_model.compile(metrics= ['accuracy'],optimizer='adam',loss='categorical_crossentropy')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T16:50:07.410377Z","iopub.execute_input":"2025-02-24T16:50:07.410684Z","iopub.status.idle":"2025-02-24T16:50:07.423507Z","shell.execute_reply.started":"2025-02-24T16:50:07.410660Z","shell.execute_reply":"2025-02-24T16:50:07.422672Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"#now lets fit the data to  the model \nteacher_model.fit(x_train_first,y_train_first,validation_data = (x_test_first,y_test_first),verbose =1 ,batch_size = 50,epochs=20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T16:50:09.876061Z","iopub.execute_input":"2025-02-24T16:50:09.876402Z","iopub.status.idle":"2025-02-24T16:56:22.852443Z","shell.execute_reply.started":"2025-02-24T16:50:09.876375Z","shell.execute_reply":"2025-02-24T16:56:22.851504Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 23ms/step - accuracy: 0.7959 - loss: 0.6556 - val_accuracy: 0.8876 - val_loss: 0.4268\nEpoch 2/20\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.9242 - loss: 0.2680 - val_accuracy: 0.9019 - val_loss: 0.3698\nEpoch 3/20\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - accuracy: 0.9449 - loss: 0.1960 - val_accuracy: 0.9411 - val_loss: 0.2621\nEpoch 4/20\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.9586 - loss: 0.1518 - val_accuracy: 0.9581 - val_loss: 0.1688\nEpoch 5/20\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.9636 - loss: 0.1312 - val_accuracy: 0.9593 - val_loss: 0.2119\nEpoch 6/20\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.9679 - loss: 0.1217 - val_accuracy: 0.9461 - val_loss: 0.6609\nEpoch 7/20\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - accuracy: 0.9722 - loss: 0.1040 - val_accuracy: 0.9669 - val_loss: 0.1474\nEpoch 8/20\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - accuracy: 0.9775 - loss: 0.0851 - val_accuracy: 0.9576 - val_loss: 0.2177\nEpoch 9/20\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.9777 - loss: 0.0808 - val_accuracy: 0.9613 - val_loss: 0.1483\nEpoch 10/20\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - accuracy: 0.9799 - loss: 0.0802 - val_accuracy: 0.9651 - val_loss: 0.1449\nEpoch 11/20\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.9783 - loss: 0.0817 - val_accuracy: 0.9697 - val_loss: 0.1407\nEpoch 12/20\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - accuracy: 0.9824 - loss: 0.0691 - val_accuracy: 0.9710 - val_loss: 0.1188\nEpoch 13/20\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.9866 - loss: 0.0482 - val_accuracy: 0.9747 - val_loss: 0.1209\nEpoch 14/20\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.9865 - loss: 0.0526 - val_accuracy: 0.9650 - val_loss: 0.2410\nEpoch 15/20\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - accuracy: 0.9871 - loss: 0.0484 - val_accuracy: 0.9677 - val_loss: 0.1309\nEpoch 16/20\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.9900 - loss: 0.0387 - val_accuracy: 0.9653 - val_loss: 0.3570\nEpoch 17/20\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.9891 - loss: 0.0445 - val_accuracy: 0.9737 - val_loss: 0.1142\nEpoch 18/20\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.9905 - loss: 0.0364 - val_accuracy: 0.9743 - val_loss: 0.1329\nEpoch 19/20\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - accuracy: 0.9920 - loss: 0.0312 - val_accuracy: 0.9717 - val_loss: 0.2027\nEpoch 20/20\n\u001b[1m800/800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.9915 - loss: 0.0304 - val_accuracy: 0.9744 - val_loss: 0.1296\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7ee12b3f4400>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"#now we have created and trained the teacher netowork lets now create a shallow network which is the student network\ninput = Input(shape = (28,28))\nflatten_layer= Flatten()(input)\ndense1= Dense(700,activation= 'relu')(flatten_layer)\ndense2= Dense(600,activation = 'relu')(dense1)\ndense3= Dense(100,activation ='relu')(dense2)\ndense4= Dense(10,activation='sigmoid')(dense3)\n\n#now lets wrap the above model b\nstudent_model = Model(inputs = input,outputs= dense4)\nstudent_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T17:07:01.863383Z","iopub.execute_input":"2025-02-24T17:07:01.863691Z","iopub.status.idle":"2025-02-24T17:07:01.918290Z","shell.execute_reply.started":"2025-02-24T17:07:01.863668Z","shell.execute_reply":"2025-02-24T17:07:01.917565Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m700\u001b[0m)                 │         \u001b[38;5;34m549,500\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m600\u001b[0m)                 │         \u001b[38;5;34m420,600\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m60,100\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,010\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">700</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">549,500</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">420,600</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">60,100</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,031,210\u001b[0m (3.93 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,031,210</span> (3.93 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,031,210\u001b[0m (3.93 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,031,210</span> (3.93 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"import tensorflow as tf\n\n# Example dataset (replace with actual dataset)\nbatch_size = 32\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((x_train,)).batch(batch_size)\n\n# Define student and teacher models\nstudent_model.compile(optimizer=tf.keras.optimizers.Adam(), loss='mse')\n\n# Define distillation loss function\ndef distillation_mse_loss(student_logits, teacher_logits):\n    return tf.reduce_mean(tf.keras.losses.MSE(teacher_logits, student_logits))\n\n# Training loop\nepochs = 5\nfor epoch in range(epochs):\n    for step, (batch_inputs,) in enumerate(train_dataset):\n        with tf.GradientTape() as tape:\n            # Get teacher logits (without softmax)\n            teacher_logits = teacher_model(batch_inputs, training=False)\n\n            # Get student logits\n            student_logits = student_model(batch_inputs, training=True)\n\n            # Compute MSE loss\n            loss = distillation_mse_loss(student_logits, teacher_logits)\n\n        # Backpropagation\n        grads = tape.gradient(loss, student_model.trainable_variables)\n        student_model.optimizer.apply_gradients(zip(grads, student_model.trainable_variables))\n\n        if step % 100 == 0:\n            print(f\"Epoch {epoch+1}, Step {step}, Loss: {loss.numpy():.4f}\")\n\n# Save the student model\nstudent_model.save(\"student_model.h5\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T17:07:06.065228Z","iopub.execute_input":"2025-02-24T17:07:06.065581Z","iopub.status.idle":"2025-02-24T17:21:11.488045Z","shell.execute_reply.started":"2025-02-24T17:07:06.065552Z","shell.execute_reply":"2025-02-24T17:21:11.487263Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Step 0, Loss: 0.3561\nEpoch 1, Step 100, Loss: 0.2685\nEpoch 1, Step 200, Loss: 0.2611\nEpoch 1, Step 300, Loss: 0.2341\nEpoch 1, Step 400, Loss: 0.2309\nEpoch 1, Step 500, Loss: 0.2324\nEpoch 1, Step 600, Loss: 0.2781\nEpoch 1, Step 700, Loss: 0.2652\nEpoch 1, Step 800, Loss: 0.2759\nEpoch 1, Step 900, Loss: 0.2577\nEpoch 1, Step 1000, Loss: 0.2640\nEpoch 1, Step 1100, Loss: 0.2735\nEpoch 1, Step 1200, Loss: 0.2507\nEpoch 1, Step 1300, Loss: 0.2851\nEpoch 1, Step 1400, Loss: 0.2583\nEpoch 1, Step 1500, Loss: 0.2694\nEpoch 1, Step 1600, Loss: 0.2848\nEpoch 1, Step 1700, Loss: 0.2758\nEpoch 1, Step 1800, Loss: 0.2302\nEpoch 2, Step 0, Loss: 0.2535\nEpoch 2, Step 100, Loss: 0.2685\nEpoch 2, Step 200, Loss: 0.2611\nEpoch 2, Step 300, Loss: 0.2341\nEpoch 2, Step 400, Loss: 0.2309\nEpoch 2, Step 500, Loss: 0.2324\nEpoch 2, Step 600, Loss: 0.2781\nEpoch 2, Step 700, Loss: 0.2652\nEpoch 2, Step 800, Loss: 0.2759\nEpoch 2, Step 900, Loss: 0.2577\nEpoch 2, Step 1000, Loss: 0.2640\nEpoch 2, Step 1100, Loss: 0.2735\nEpoch 2, Step 1200, Loss: 0.2507\nEpoch 2, Step 1300, Loss: 0.2851\nEpoch 2, Step 1400, Loss: 0.2583\nEpoch 2, Step 1500, Loss: 0.2694\nEpoch 2, Step 1600, Loss: 0.2848\nEpoch 2, Step 1700, Loss: 0.2758\nEpoch 2, Step 1800, Loss: 0.2302\nEpoch 3, Step 0, Loss: 0.2535\nEpoch 3, Step 100, Loss: 0.2685\nEpoch 3, Step 200, Loss: 0.2611\nEpoch 3, Step 300, Loss: 0.2341\nEpoch 3, Step 400, Loss: 0.2309\nEpoch 3, Step 500, Loss: 0.2324\nEpoch 3, Step 600, Loss: 0.2781\nEpoch 3, Step 700, Loss: 0.2652\nEpoch 3, Step 800, Loss: 0.2759\nEpoch 3, Step 900, Loss: 0.2577\nEpoch 3, Step 1000, Loss: 0.2640\nEpoch 3, Step 1100, Loss: 0.2735\nEpoch 3, Step 1200, Loss: 0.2507\nEpoch 3, Step 1300, Loss: 0.2851\nEpoch 3, Step 1400, Loss: 0.2583\nEpoch 3, Step 1500, Loss: 0.2694\nEpoch 3, Step 1600, Loss: 0.2848\nEpoch 3, Step 1700, Loss: 0.2758\nEpoch 3, Step 1800, Loss: 0.2302\nEpoch 4, Step 0, Loss: 0.2535\nEpoch 4, Step 100, Loss: 0.2685\nEpoch 4, Step 200, Loss: 0.2611\nEpoch 4, Step 300, Loss: 0.2341\nEpoch 4, Step 400, Loss: 0.2309\nEpoch 4, Step 500, Loss: 0.2324\nEpoch 4, Step 600, Loss: 0.2781\nEpoch 4, Step 700, Loss: 0.2652\nEpoch 4, Step 800, Loss: 0.2759\nEpoch 4, Step 900, Loss: 0.2577\nEpoch 4, Step 1000, Loss: 0.2640\nEpoch 4, Step 1100, Loss: 0.2735\nEpoch 4, Step 1200, Loss: 0.2507\nEpoch 4, Step 1300, Loss: 0.2851\nEpoch 4, Step 1400, Loss: 0.2583\nEpoch 4, Step 1500, Loss: 0.2694\nEpoch 4, Step 1600, Loss: 0.2848\nEpoch 4, Step 1700, Loss: 0.2758\nEpoch 4, Step 1800, Loss: 0.2302\nEpoch 5, Step 0, Loss: 0.2535\nEpoch 5, Step 100, Loss: 0.2685\nEpoch 5, Step 200, Loss: 0.2611\nEpoch 5, Step 300, Loss: 0.2341\nEpoch 5, Step 400, Loss: 0.2309\nEpoch 5, Step 500, Loss: 0.2324\nEpoch 5, Step 600, Loss: 0.2781\nEpoch 5, Step 700, Loss: 0.2652\nEpoch 5, Step 800, Loss: 0.2759\nEpoch 5, Step 900, Loss: 0.2577\nEpoch 5, Step 1000, Loss: 0.2640\nEpoch 5, Step 1100, Loss: 0.2735\nEpoch 5, Step 1200, Loss: 0.2507\nEpoch 5, Step 1300, Loss: 0.2851\nEpoch 5, Step 1400, Loss: 0.2583\nEpoch 5, Step 1500, Loss: 0.2694\nEpoch 5, Step 1600, Loss: 0.2848\nEpoch 5, Step 1700, Loss: 0.2758\nEpoch 5, Step 1800, Loss: 0.2302\n","output_type":"stream"}],"execution_count":10}]}